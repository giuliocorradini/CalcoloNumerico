# Sistemi lineari

Si prestano a essere descritti sotto la forma matriciale: le incognite sono scritte in ordine
e con una notazione a indice (quella alfabetica non ha senso per >= 4 variabili).

La matrice che rappresenta il sistema è $A \in \R ^ {mxn}$, la soluzione al sistema è un vettore in dimensione
n che soddisfa la relazione:

$Ax = b$

Dove x è il vettore colonna delle incognite, mentre b è il vettore colonna dei termini noti.

Un esempio d'uso è l'applicazione delle leggi di Kirchoff per l'analisi di un circuito elettrico.

### Sistemi sottodeterminati

Noi ci occuperemo di sistemi lineari quadrati. Quelli invece rettangolari, sottodeterminati, per cui abbiamo
infinite soluzioni, si affrontano in modo simile ma dopo aver battezzato i gradi liberi.

Alcune componenti diventano parametri.
Tipicamente non c'è una soluzione, quindi bisogna fare delle approssimazioni.

## Condizionamento

Prima di cercare una soluzione, guardiamo i dati del problema che stiamo risolvendo. Che informazioni
possiamo ricavare sul condizionamento del problema?

Prendiamo una matrice H del tipo $H_{ij} = \frac{1}{i+j-1}$, proviamo a vedere quanto la soluzione elaborata
dal calcolatore dista dal vettore soluzione (1, ..., 1).
Questo lo faccio per n crescente.

Ci accorgiamo di come per una pertubazione piccola (nell'ordine di 10^-10), abbiamo grandissime variazioni
sui risulati.

Vedi `hilbert.m`.

Un sistema lineare è malcondizionato quando le equazioni dl sistema (ovvero le righe della matrice) sono
quasi linearmente dipendenti. I coefficienti della matrice non sono proprio casuali.

### Soluzioni

Una matrice quadrata si dice invertibile se esiste una matrice X tale che $XA = AX = I$.
La matrice $X = A^{-1}$ prende il nome di matrice inversa.

Sono proprietà equivalenti all'invertibilità:

- A è non singolare;

- $det(A) \ne 0$ e nel caso della matrice quadrata è il rango della matrice;

- le righe sono linearmente indipendenti e le colonne sono linearmente indipendenti;

- $A \vec x = 0 \Leftrightarrow \vec x =0$

Se ho quasi linearità vuol dire che due rette (due righe) sono quasi coincidenti. Quello che
succede traslando le due rette (shifto la retta di un poco) è che se l'angolo è basso,
il punto mi si sposterà di molto sulle x (spiegazione geometrica).

Quindi senza perturbazioni artificiose avremmo counque degli errori, perché entra in gioco
la precisione di macchina. Il problema è comunque malcondizionato.

Con la matrice di Hilbert abbiamo un'amplificazione di 17 ordini sulle perturbazioni. Se la perturbazione
è l'errore di macchina (10^-16) allora mi troverò anche un errore di 10 volte la soluzione.

Si può usare il determinante di una matrice come indicatore del condizionamento? Se è vicino a 0 la matrice
potrebbe essere malcondizionata. No, non si può perché esistono casi in cui la matrice è ben condizionata
e il determinante è vicino a 0. Ad esempio nel caso di $S = \frac{1}{2} I$, $det(S) = \frac{1}{2^n}$.

Per fortuna c'è modo di prevedere le cose se sappiamo che esistono. Da dove viene fuori questo
10^17? Perché se è prevedibile possiamo correggerlo.

$Ax = b$

$A \tilde{x} = b + \Delta b$

Uniamo le relazioni (facciamo finta di essere in un mondo risolvibile):

$$A \tilde{x} = Ax + \Delta b \Rightarrow A(\tilde{x} - x) = \Delta b$$

$$A^{-1} A(\tilde{x} - x) = A^{-1} \Delta b \Rightarrow (\tilde{x} - x) = A^{-1} \Delta b$$

adesso applichiamo la norma vettoriale

$$||\tilde{x} - x|| = ||A^{-1} \Delta b||$$

e se facciamo la scelta di norme vettoriali e matriciali compatibili possiamo maggiorare l'equazione
con questa relazione

$$||\tilde{x} - x|| = ||A^{-1} \Delta b|| \le ||A^{-1}|| \cdot ||\Delta b||$$

Usiamo l'altra relazione

$$b = Ax \Rightarrow ||b|| = ||Ax|| \le ||A||\ ||x||$$

divido tutto per $||x||$, quindi $\frac{1}{||x||} \le ||A|| \frac{1}{||b||}$

Quindi possiamo scrivere che:

$$
\frac{||\tilde{x} - x||}{||x||} \le ||A||\ ||A^{-1}||\ \frac{||\Delta b||}{||b||}
$$

ricordandoci che $\frac{||\Delta b||}{||b||} = \epsilon _b$

Quindi il coefficiente di amplificazione che avevamo indicato col punto di domanda è proprio il termine $k(A) = ||A||\ ||A^{-1}||$ che viene detto _numero di condizionamento_ della la matrice A.

Se perturbiamo anche la matrice A, possiamo dimostrare che l'errore relativo inerente viene maggiorato da:

$$
\frac{|| \tilde x - x^*||}{||x^*||} \le \frac{k(A)}{1-k(A)e_A} (e_A + e_b)
$$
