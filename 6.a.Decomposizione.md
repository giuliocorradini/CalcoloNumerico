# Metodi di decomposizione

Sono una sottofamiglia dei metodi iterativi di risoluzione dei sistemi lineari.
Si dicono _di decomposizione_ perché andiamo a smontare la matrice.

![Famiglie di metodi](famiglie_di_metodi.svg)

La decomposizione di A è basata sulla differenza di due matrici: M e N.

$$A = M - N$$

Scegliendo M come matrice del metodo: $MX = Nx - b$ (N è automaticamente determinata, N = M - A).

Alla prima iterazione: $M x^{(1)} = N x^{(0)} + b$. Quello che ottengo è un vettore $p = Nx - b$.

Quindi $Mx^{(1)} = p$ e l 'ultima cosa da fare è risolvere il sistema lineare.

In generale al passo k:

$$
M x^{(k+1)} = N x^{(k)} + b
$$

La matrice M va scelta in modo che si possa ottenere una soluzione al sistema dal basso costo computazionale.

Per le famiglie di metodi di Jacobi e Gauss-Seidel, andiamo a decomporre in tre matrici e le combiniamo in due
modi diversi.

$$
A = D - E - F
$$

La matrice D è la diagonale di A

$$
D = \begin{pmatrix} a_{11} & 0 & \dots & 0\\0 & a_{22} & \dots & 0\\\vdots & \vdots & \ddots & \vdots\\0 & 0 & \dots & a_{nn}\\ \end{pmatrix}
$$

E è il triangolo inferiore di A cambiato di segno

$$
E = \begin{pmatrix} 0 & 0 & \dots & 0\\-a_{21} & 0 & \dots & 0\\\vdots & \vdots & \ddots & \vdots\\-a_{n1} & -a_{n2} & \dots & 0\\ \end{pmatrix}
$$

F è il triangolo superiore cambiato di segno

$$
F = \begin{pmatrix} 0 & -a_{12} & \dots & -a_{1n}\\0 & 0 & \dots & -a_{2n}\\\vdots & \vdots & \ddots & \vdots\\0 & 0 & \dots & 0\\ \end{pmatrix}
$$

Il metodo di Jacobi predilige $M = D$, di conseguenza $N = E + F$. Mentre Gauss-Seidel usa $M = D-E$ e $N=F$.

# Metodo di Jacobi

$$M = D, N = E + F$$

$$Ax = b$$

$$Mx = Nx + b$$

$$Dx^{(k+1)} = (E+F) x^{(k)} + b$$

Implementato per componenti:

$d := diag(D) = \begin{pmatrix} a_{11} & a_{22} & \dots & a_{nn}\\ \end{pmatrix}$

$x^{(k+1)} = [(E+F) x^{(k)} + b] ./ d$

$$
\begin{pmatrix} x^{(k+1)}_{1}\\x^{(k+1)}_{2}\\\vdots\\x^{(k+1)}_{n}\\ \end{pmatrix}

=

[

\begin{pmatrix} 0 & a_{12} & \dots & a_{1n}\\a_{21} & 0 & \dots & a_{2n}\\\vdots & \vdots & \ddots & \vdots\\a_{n1} & a_{n2} & \dots & 0\\ \end{pmatrix}

\begin{pmatrix} x^{(k)}_{1} \\ x^{(k)}_{2} \\ \dots \\ x^{(k)}_{n}  \end{pmatrix}

+

\begin{pmatrix} b_{1} \\ b_{2} \\ \dots \\ b_{n}  \end{pmatrix}

] /

\begin{pmatrix} a_{11}\\a_{22}\\\vdots\\a_{nn}\\ \end{pmatrix}
$$

per cui:

$$x_i^{(k+1)} = (b_i - \sum_{j=1,j\ne i}^{n} a_{ij} x_j^{(k)}) / a_{ii}, i = 1, \dots, n$$

Ogni componente di questa iterata $x^{(k+1)}$ si calcola sono in funzione dell'elemento dell'iterata precedente x^{(k)}.

Il metodo di Jacobi è parallelizzabile, mentre Gauss-Seidel usa il metodo degli spostamenti successivi (per cui la
soluzione corrente dipende anche dall'iterazione corrente) e quindi non è parallelizzabile.