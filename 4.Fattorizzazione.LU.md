# Fattorizzazione LU

e metodi di risoluzione dei sistemi lineari.

## Sostituzione

[Triangular Solve in Matlab](MatlabFunctions/triusolve.m)

L'approssimazione che si commette a risolvere un sistema con Matlab è:

$\tilde{x}_1 = fl(b_1/l_{11})=\frac{b_1}{l_11}(1+\epsilon_1) = x_1^* (1+\epsilon_1)$

Invece per $\tilde{x}_2$ abbiamo un approssimazione di $x^*_2 + \frac{l_{21} x^*_1}{l_{22}} \epsilon_1$.

L'errore aumenta se $l_{21} >> l_{22}$, se invece è molto più piccolo si ha stabilità.

In conclusione: gli algoritmi che operano per sostituzione diventano molto instabili se non sono soddisfatte
le condizioni sugli elementi della matrice.

## Cramer

Poco efficiente perché devo calcolare un determinate per ogni elemento della matrice, più uno.
Il costo è n! quando utilizzo la regola di Laplace per il calcolo del determinante.

$$
A = \begin{pmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33} \end{pmatrix}
$$

per trovare una soluzione i-esima sostituisco alla colonna i-esima i termini noti.

$$
x_1 = \frac{
    \begin{pmatrix} b_1 & a_{12} & a_{13} \\ b_2 & a_{22} & a_{23} \\ b_3 & a_{32} & a_{33} \end{pmatrix}
}{det(A)}
$$

## Gauss

Il metodo di Gauss permette di trovare una matrice triangolare inferiore L e una superiore U, che fattorizzano
A matrice dei termini noti.

$$A = LU$$

quindi

$$LUx = b \Rightarrow Ly = b$$

Adesso costruisco un sistema triangolare equivalente a quello iniziale. Il sistema si riscrive come:

$$Ly = b$$

$$Ux = y$$

### Passi di eliminazione

I passi di eliminazione sono $n-1$ (devo azzerare fino alla penultima sottocolonna).

### Combinazione lineare di vettori

Presi $v = (v_1, v_2, v_3, v_4)$ e $u = (u_1, u_2, u_3, u_4)$ e uno scalare $r \in R$, fare la combinazione
$u + rv$ significa fare: $(u_1 + rv_1, u_2+rv_2, u3+rv_3, u_4+rv_4)$.


Per ogni passo prendiamo il primo elemento della colonna che stiamo considerando e lo chiamiamo **pivot**.
I moltiplicatori sono gli $m_i = \frac{a_{i1}}{a_{11}}$. Poi moltiplico la riga i con la riga 1 e coefficiente $-m_{i1}$
per i che va da 2 a n.

Dopo questi passaggi ho ottenuto una matrice triangolare superiore U.

Le operazioni fatte a ogni passo possiamo riassumerle in n-1 matrici triangolari inferiori.
Mi dice che operazioni devo fare per annullare la k-esima sottocolonna.

Il procedimento è ben posto solo se $a_{kk}^{(k)} \neq 0$, elemento pivottante del passo k-esimo.

### Trucco di ottimizzazione

Per migliorare l'uso di memoria, posso sovrascrivere su A i molitplicatori e i valori di U.
L e U sono nella stessa matrice.

$$ %TODO
L_k =
\begin{pmatrix}

\end{pmatrix}
$$

In totale per la matrice il costo è $O(n^3/3)$ dato dalle somme e prodotti, i quoziente chiedono $O(n^2/2)$.

La U viene ottenuta in questo modo:

$$U = L_{n-1} A_{n-1} = \dots = L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1 \ A_1 (= A)$$

adesso devo dimostrare che L è una matrice triangolare inferiore. So che al passo k ho la matrice identica
con i moltiplicatore sotto all'1 nella colonna k-esima. Notiamo che se moltiplichiamo due matrici triangolari
superiori otteniamo ancora una matrice triangolare superiore.

$L_k$ è triangolare con diagonale unitaria $\Rightarrow det(L_k) = 1$. Dimostriamolo per un qualsiasi n.
Supponiamo che sia vero per $n = k$, allora è vero anche per $n = k+1$?

Al passo $n=k$ il determinante vale 1 per ipotesi.

$$
det \begin{pmatrix} 1 & 0 & ... & 0 \\ l_{21} & 1 & ... & 0 \\ \vdots & \vdots & \ddots & \vdots \\ l_{k1} & l_{k2} & ... & 1 \\ \end{pmatrix} = 1
$$

andiamo al passo k+1.

$$
det \begin{pmatrix} 1 & 0 & ... & 0 \\ l_{21} & 1 & ... & 0 \\ \vdots & \vdots & \ddots & \vdots \\ l_{k+1\ 1} & l_{k+1\ 2} & ... & 1 \\ \end{pmatrix}
$$

applicando Laplace a $l_{k+1\ k+1}$ trovo $l_{k+1\ k+1} * det(N)$ cioè la matrice precedente: ho dimostrato la tesi.

La matrice non è singolare perché non ha il determinante uguale a 0, quindi la posso invertire.

**Importante**

In una generica $L_k$ ho valori diversi da 0 (a parte la diagonale unitaria) sulla k-esima colonna. Allora posso riscriverla banalmente come somma
di 2 matrici. Come $I_{k x k}$ e poi una matrice che ha 0 ovunque, tranne nella colonna k-esima dove ha l'inverso dei moltiplicatori.

Come si genera una matrice siffatta? Prendo la colonna che mi serve e la moltiplico per la riga con 1 nella posizione target della colonna.

$%TODO manim animation of this matrix product$

Dimostriamo che l'inversa $L_k^{-1} = (I + m^{(k)} e_k^T)$ ha solo i moltiplicatori cambiati di segno. Matrice e matrice inversa devono dare l'identità...

$$
(I - m^{(k)} e_k^T) (I + m^{(k)} e_k^T) = I - m^{(k)}e_k^T + m^{(k)}e_k^T - m^{(k)}e_k^T m^{(k)}e_k^T = I
$$

visto che $m^{(k)}e_k^Tm^{(k)}e_k^T = 0$ perché $e_k^Tm^{(k)} = 0$.

Moltiplico prima i due centrali perché così mi viene fuori uno scalare (ho 1xn per nx1),
l'unico prodotto che non viene 0 è quello in posizione k (perché nella riga ho 1 in posizione k),
ma lo sto moltplicando per uno 0 nella colonna, visto che i moltiplicatori cominciano dalla posizione k+1.

Mi interessa anche il prodotto delle inverse. Eravamo rimasti a $U = L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1 \ A$
e considero $L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1$ come un'unica matrice; siccome hanno tutte il determinante
1 allora esiste l'inversa (il prodotto delle matrici produce una matrice col determinante che è il prodotto
dei determinanti).

Per "portarla di là" devo moltiplicare entrambi i termini per l'inverso $(L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1) ^ {-1}$.

A questo punto ho ottenuto $(L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1) ^ {-1}\ U = A$, così abbiamo trovato
la candidata a L per la fattorizzazione LU.

$(L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1) ^ {-1} = L_1 ^{-1} \ L_2^{-1} \ \dots \ L_{n-2}^{-1} \ L_{n-1}^{-1}$.

Moltiplicare queste matrici triangoli inferiori signfica "semplicemente" sommare l'identità con le colonne dei
moltiplicatori nella loro posizione j-esima.

Dimostrazione:

$$
L_k^{-1} L_j^{-1} = (I + m^{(k)} e_k^T) (I + m^{(j)} e_k^T)
$$
$$
= I + m^{(k)}e_k^T + m^{(j)}e_j^T k m^{(k)}e_k^T m^{(j)}e_j^T
$$
$$
= I + m^{(k)}e_k^T + m^{(j)}e_j^T
$$

di nuovo come prima $e_k^T m^{(j)} = 0$ perché se $k \lt j+1$ $%todo finisci%$.

Abbiamo _finalmente_ ottenuto la decomposizione che stiamo cercando. Ho disaccoppiato il mio sistema
in due triangolari, che posso risolvere con sostituzione in avanti e all'indietro.
Prima risolvo la relazione $Ly = b$ perché y mi serve come colonna dei termini noti nella seconda relazione.

## Problema del pivot

C'è un problema: abbiamo messo un'ipotesi molto pesante, cioè che ogni pivot sia diverso da 0.
Adesso dobbiamo riscrivere la condizione in modo equivalente ma più semplice da verificare.

Controlliamo i minori principali, se trovo anche solo un elemento uguale a 0 a parte l'ultimo, allora il determinante
diventerà uguale a 0 quindi il mio sistema ha due righe linearmente dipendenti (ed è sottodimensionato).

La fattorizzazione è unica a meno di una costante.
