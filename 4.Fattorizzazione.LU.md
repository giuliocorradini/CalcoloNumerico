# Fattorizzazione LU

e metodi di risoluzione dei sistemi lineari.

## Sostituzione

[Triangular Solve in Matlab](MatlabFunctions/triusolve.m)

L'approssimazione che si commette a risolvere un sistema con Matlab è:

$\tilde{x}_1 = fl(b_1/l_{11})=\frac{b_1}{l_11}(1+\epsilon_1) = x_1^* (1+\epsilon_1)$

Invece per $\tilde{x}_2$ abbiamo un approssimazione di $x^*_2 + \frac{l_{21} x^*_1}{l_{22}} \epsilon_1$.

L'errore aumenta se $l_{21} >> l_{22}$, se invece è molto più piccolo si ha stabilità.

In conclusione: gli algoritmi che operano per sostituzione diventano molto instabili se non sono soddisfatte
le condizioni sugli elementi della matrice.

## Cramer

Poco efficiente perché devo calcolare un determinate per ogni elemento della matrice, più uno.
Il costo è n! quando utilizzo la regola di Laplace per il calcolo del determinante.

$$
A = \begin{pmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33} \end{pmatrix}
$$

per trovare una soluzione i-esima sostituisco alla colonna i-esima i termini noti.

$$
x_1 = \frac{
    \begin{pmatrix} b_1 & a_{12} & a_{13} \\ b_2 & a_{22} & a_{23} \\ b_3 & a_{32} & a_{33} \end{pmatrix}
}{det(A)}
$$

## Gauss

Il metodo di Gauss permette di trovare una matrice triangolare inferiore L e una superiore U, che fattorizzano
A matrice dei termini noti.

$$A = LU$$

quindi

$$LUx = b \Rightarrow Ly = b$$

Adesso costruisco un sistema triangolare equivalente a quello iniziale. Il sistema si riscrive come:

$$Ly = b$$

$$Ux = y$$

e la soluzione si ottiene risolvendo $Ly = b$ per sostituzione in avanti, e $Ux = y$ per sostituzione all'indietro.

### Passi di eliminazione

I passi di eliminazione sono $n-1$ (devo azzerare fino alla penultima sottocolonna). L'obiettivo è annullare le
sottocolonne della diagonale principale.

### Combinazione lineare di vettori

Presi $v = (v_1, v_2, v_3, v_4)$ e $u = (u_1, u_2, u_3, u_4)$ e uno scalare $r \in R$, fare la combinazione
$u + rv$ significa fare: $(u_1 + rv_1, u_2+rv_2, u3+rv_3, u_4+rv_4)$.


Per ogni passo prendiamo il primo elemento della colonna che stiamo considerando e lo chiamiamo **pivot**.
I moltiplicatori sono gli $m_i = \frac{a_{i1}}{a_{11}}$. Poi moltiplico la riga i con la riga 1 e coefficiente $-m_{i1}$
per i che va da 2 a n.

Dopo questi passaggi ho ottenuto una matrice triangolare superiore U.

Le operazioni fatte a ogni passo possiamo riassumerle in n-1 matrici triangolari inferiori.
Mi dice che operazioni devo fare per annullare la k-esima sottocolonna.

Il procedimento è ben posto solo se $a_{kk}^{(k)} \neq 0$, elemento pivottante del passo k-esimo.

### Trucco di ottimizzazione

Per migliorare l'uso di memoria, posso sovrascrivere su A i molitplicatori e i valori di U.
L e U sono nella stessa matrice.

```matlab
for k = 1 : n-1
    for i = k+1 : n
        A(i, k) = A(i, k) / A(k, k);

        for j = k+1 : n
            A(i, j) = A(i, j) - A(i, k) * A(k, j)
        end
    end
end
```

se voglio riscriverlo più compatto

```matlab
for k = 1 : n-1
    A(k+1:n, k) = A(k+1:n, k) ./ A(k, k);
    A(k+1:n, k+1:n) = A(k+1:n, k+1:n) - A(k+1:n, k) * A(k, k+1:n);
end
```

In totale per la matrice il costo è $O(n^3/3)$ dato dalle somme e prodotti, i quozienti
richiedono $O(n^2/2)$.

La U viene ottenuta in questo modo:

$$U = L_{n-1} A_{n-1} = \dots = L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1 \ A_1 (= A)$$

e possiamo quindi scrivere

$$
L_{n-1}L_{n-2} ... L_2L_1A = U
$$

quindi

$$
A = (L_{n-1}L_{n-2} ... L_2L_1) ^ {-1} U \\
A = L_1^{-1} L_2^{-1}  ... L_{n-2}^{-1} L_{n-1}^{-1} U
$$

perciò definisco $L=L_1^{-1} L_2^{-1}  ... L_{n-2}^{-1} L_{n-1}^{-1}$

## Dimostrazione

Adesso devo dimostrare che L è una matrice triangolare inferiore nonsingolare, ottenuta da prodotto di matrici
triangolari inferiori nonsingolari, ovvero le $L_k^{-1}$.

So che al passo k ho la matrice identica con i moltiplicatori sotto all'1 nella colonna k-esima.
Notiamo che se moltiplichiamo due matrici triangolari inferiori otteniamo ancora una matrice triangolare inferiore.

$L_k$ è triangolare con diagonale unitaria $\Rightarrow det(L_k) = 1$. Dimostriamolo per un qualsiasi n.

Supponiamo che sia vero per $n = k$, allora è vero anche per $n = k+1$?

Al passo $n=k$ il determinante vale 1 per ipotesi.

$$
det \begin{pmatrix} 1 & 0 & ... & 0 \\ l_{21} & 1 & ... & 0 \\ \vdots & \vdots & \ddots & \vdots \\ l_{k1} & l_{k2} & ... & 1 \\ \end{pmatrix} = 1
$$

andiamo al passo k+1.

$$
det \begin{pmatrix} 1 & 0 & ... & 0 \\ l_{21} & 1 & ... & 0 \\ \vdots & \vdots & \ddots & \vdots \\ l_{k+1\ 1} & l_{k+1\ 2} & ... & 1 \\ \end{pmatrix}
$$

applicando Laplace a $l_{k+1\ k+1}$ trovo $l_{k+1\ k+1} * det(N)$ cioè la matrice precedente: ho dimostrato la tesi.

La matrice non è singolare perché non ha il determinante uguale a 0, quindi la posso invertire.

La matrice $L_k$ si ottiene così: $I - m^{(k)} \cdot e_k$, dove $m^{(k)}$ è la colonna dei moltiplicatori al passo k,
mentre $e_k$ è il k-esimo vettore canonico dello spazio $\mathbb{R}^n$ preso come riga.

Moltiplicare una colonna per il k-esimo vettore canonico siginifica generare una matrice con la colonna moltiplicante
nella colonna k-esima della matrice.

### Inversa di una trasformazione elementare di Gauss

L'inversa della k-esima trasformazione elementare di Gauss $L^{-1}_{k}$ è $I + m^{(k)} e_k$.

Dimostrazione:

$$
(I + m^{(k)} e_k) (I - m^{(k)} e_k) = \\
I - I m^{(k)} e_k + m^{(k)} e_kI - m^{(k)} e_k m^{(k)} e_k = \\
I - m^{(k)} e_k + m^{(k)} e_k - m^{(k)} 0 e_k \\
$$

$$
(I + m^{(k)} e_k) (I - m^{(k)} e_k) = I
$$

> una nota sulla moltiplicazione $e_k m^{(k)}$, il risultato è il prodotto elemento per elemento dove l'unico 1 del
> vettore canonico si trova nella posizione k-esima, ma nella colonna dei moltiplicatori quella colonna ha valore 0.

**Spiegazione lunga**

In una generica $L_k$ ho valori diversi da 0 (a parte la diagonale unitaria) sulla k-esima colonna. Allora posso riscriverla banalmente come somma
di 2 matrici. Come $I_{k x k}$ e poi una matrice che ha 0 ovunque, tranne nella colonna k-esima dove ha l'inverso dei moltiplicatori.

Come si genera una matrice siffatta? Prendo la colonna che mi serve e la moltiplico per la riga con 1 nella posizione target della colonna.

Dimostriamo che l'inversa $L_k^{-1} = (I + m^{(k)} e_k^T)$ ha solo i moltiplicatori cambiati di segno. Matrice e matrice inversa devono dare l'identità...

$$
(I - m^{(k)} e_k^T) (I + m^{(k)} e_k^T) = I - m^{(k)}e_k^T + m^{(k)}e_k^T - m^{(k)}e_k^T m^{(k)}e_k^T = I
$$

visto che $m^{(k)}e_k^Tm^{(k)}e_k^T = 0$ perché $e_k^Tm^{(k)} = 0$.

Moltiplico prima i due centrali perché così mi viene fuori uno scalare (ho 1xn per nx1),
l'unico prodotto che non viene 0 è quello in posizione k (perché nella riga ho 1 in posizione k),
ma lo sto moltplicando per uno 0 nella colonna, visto che i moltiplicatori cominciano dalla posizione k+1.

### Prodotto delle inverse delle trasformazioni

Il prodotto delle inverse delle trasformazioni $L_i \cdot L_j$ è uguale alla somma tra la matrice identità e le colonne
dei moltiplicatori in posizione i e j.

Dimostrazione:

$$
L_k ^ {-1} \cdot L_j ^ {-1} = \\
(I + m^{(k)} e_k) \cdot (I + m^{(j)} e_j) = \\
I + I m^{(j)} e_j + m^{(k)} e_k I + m^{(k)} e_k m^{(j)} e_j = \\
I + m^{(j)} e_j + m^{(k)} e_k
$$

> Nota su $e_k m^{(j)}$, il risultato è 0 quando k < j, che è il nostro caso perché vogliamo dimostrare una proprietà
> della catena di moltiplicazioni delle inverse delle trasformazioni elementari di Gauss, che emergono in ordine inverso.

**Spiegazione lunga**

Mi interessa anche il prodotto delle inverse. Eravamo rimasti a $U = L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1 \ A$
e considero $L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1$ come un'unica matrice; siccome hanno tutte il determinante
1 allora esiste l'inversa (il prodotto delle matrici produce una matrice col determinante che è il prodotto
dei determinanti).

Per "portarla di là" devo moltiplicare entrambi i termini per l'inverso $(L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1) ^ {-1}$.

A questo punto ho ottenuto $(L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1) ^ {-1}\ U = A$, così abbiamo trovato
la candidata a L per la fattorizzazione LU.

$(L_{n-1} \ L_{n-2} \ \dots \ L_2 \ L_1) ^ {-1} = L_1 ^{-1} \ L_2^{-1} \ \dots \ L_{n-2}^{-1} \ L_{n-1}^{-1}$.

Moltiplicare queste matrici triangoli inferiori signfica "semplicemente" sommare l'identità con le colonne dei
moltiplicatori nella loro posizione j-esima.


Abbiamo _finalmente_ ottenuto la decomposizione che stiamo cercando. Ho disaccoppiato il mio sistema
in due triangolari, che posso risolvere con sostituzione in avanti e all'indietro.
Prima risolvo la relazione $Ly = b$ perché y mi serve come colonna dei termini noti nella seconda relazione.

## Costi

Fattorizzare costa $O(\frac{n^3}{3})$ mentre risolvere i due sistemi triangolari per sostituzione $2O(\frac{n^2}{2})$.

## Problema del pivot

C'è un problema: abbiamo messo un'ipotesi molto pesante, cioè che ogni pivot sia diverso da 0.
Adesso dobbiamo riscrivere la condizione in modo equivalente ma più semplice da verificare.

Controlliamo i minori principali, se trovo anche solo un elemento uguale a 0 a parte l'ultimo, allora il determinante
diventerà uguale a 0 quindi il mio sistema ha due righe linearmente dipendenti (ed è sottodimensionato).

Al k-esimo passo, il minore principale della matrice $A^{(k)}$, ovvero il determinante della sottomatrice ottenuta
prendendo le prime k righe e k colonne, equivale al prodotto degli elementi sulla diagonale principale vista la natura
triangolare della matrice.

I minori principali sono tutti diversi da zero se e solo se tutti gli elementi pivot sono diversi da 0.

$$
A^{(i)} \ne 0\ \Leftrightarrow a_{ii}^{(i)} \ne 0 \ \forall i = 1, ..., k
$$

quindi per avere tutti i pivot diversi da 0, i minori della matrice A devono essere tutti non-nulli eccetto al più
l'ultimo, perché se dovesse succedere l'algoritmo potrebbe comunque terminare ma la matrice avrebbe $detA = 0$.

Per cui se tutti i minori principali della matrice A sono diversi da 0, tranne al più l'ultimo, allora la fattorizzazione
con trasformazioni elementari di Gauss è possibile.

Ovvero è possibile trovare due matrici triangolari L e U tali che $A = LU$.

Inoltre il k-esimo minore principali è $A^{(k)} = u_{11} u_{22} ... u_{kk}$; il prodotto dei pivot.

La fattorizzazione è unica a meno di una costante.

Prendiamo una matrice A non singolare, e poniamo che esistano due fattorizzazioni $A = L_1 U_1$ e $A = L_2 U_2$,
tali che $L_1$ e $L_2$ siano non singolari.

Allora possiamo dire che

$$
L_1 U_1 = L_2 U_2 \\
L_1^{-1} L_1 U_1 = L_1^{-1} L_2 U_2 \\
U_1 U_2^{-1} = L_1^{-1} L_2 U_2 U_2^{-1} \\
U_1 U_2^{-1} = L_1^{-1} L_2 \\
$$

abbiamo quindi ottenuto un'uguaglianza tra una matrice triangolare inferiore e una matrice triangolare superiore,
che può essere verificata solo se entrambe le matrici sono diagonali.

Osserviamo che $L_1^{-1} L_2$ ha diagonale unitaria.

Per cui:

$$
I = U_1 U_2^{-1} = L_1^{-1} L_2 \\
\Rightarrow U_1 = U_2, L_1=L_2
$$
